{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read csv\n",
    "path = './data/'\n",
    "\n",
    "def get_csv(path):\n",
    "    # load CSV & drop zeros\n",
    "    df = pd.read_csv(path+'driving_log.csv')\n",
    "    df = df.drop(df[df['steering'] == 0.].index)\n",
    "    df = df.drop(df[df['speed'] < 1.].index)\n",
    "    return df\n",
    "\n",
    "df = get_csv(path = path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split\n",
    "split_index = int((1-(1/11))*(len(df)))\n",
    "df_train = df[:split_index]\n",
    "df_val  = df[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate batch\n",
    "\n",
    "#import sklearn\n",
    "image_shape = cv2.imread( path+df['center'][df['center'].index[0]]).shape\n",
    "batch_size = 5*7*7 # 3675 = 3*5*5*7*7\n",
    "\n",
    "def get_batch(df,batch_size): \n",
    "    n_split = int(len(df)//batch_size)-1\n",
    "    batch_idx = (df[:batch_size*n_split].index.values.reshape(n_split,batch_size,))\n",
    "    while 1:\n",
    "        for idx in batch_idx:\n",
    "            batch_y      =      df['steering'][idx].values\n",
    "            batch_x_path = path+df['center'  ][idx]\n",
    "            batch_x      = np.empty(list([batch_size]) + list(image_shape))\n",
    "\n",
    "            ii = 0\n",
    "            for img_path in batch_x_path:\n",
    "                image = cv2.imread(img_path)\n",
    "                batch_x[ii] = image\n",
    "                ii +=1\n",
    "\n",
    "            assert(not(np.isnan((np.sum(batch_x)))))\n",
    "            assert(not(np.isnan((np.sum(batch_y)))))\n",
    "            yield (batch_x,batch_y) \n",
    "\n",
    "train_generator = get_batch(df_train, batch_size=batch_size)\n",
    "validation_generator = get_batch(df_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def visualise_dataset(image,label,steps):\n",
    "    plt_num = 1\n",
    "    print(image.shape)\n",
    "    \n",
    "    step_size = int(image.shape[0]/steps)\n",
    "    \n",
    "    #for image_idx in range(0,image.shape[0],step_size):\n",
    "    for image_idx in range(0,image.shape[0],step_size):\n",
    "        channels = image.shape[3]\n",
    "        plt.figure(plt_num, figsize=(32,32))\n",
    "        for channel in range(channels):\n",
    "            plt.subplot(4,8, channel+1) # sets the number of feature maps to show on each row and column\n",
    "            plt.title('channel ' + str(channel)) # displays the feature map number\n",
    "            plt.imshow(image[image_idx,:,:, channel], interpolation=\"nearest\", cmap=\"gray\")\n",
    "        plt.show()\n",
    "\n",
    "        print('{1}, idx: {0}'.format(image_idx,label[image_idx],))\n",
    "        \n",
    "#%time visualise_dataset(batch_x,batch_y,steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def get_StratifiedShuffleSplit(batches_idx,batch_size):\n",
    "    n_bins  = 5\n",
    "    batch_size = 5*7*7\n",
    "    y_classes = df['steering'].copy()*n_bins//1\n",
    "    batches_idx = df.index\n",
    "    data_size = len(batches_idx)\n",
    "    n_split = int(data_size//batch_size)-1\n",
    "    print(n_split)\n",
    "    batch_range = df.index\n",
    "    sss = StratifiedShuffleSplit(n_splits = n_split,test_size = 15)\n",
    "    batch_idx, val_idx = next(sss.split((batch_range),(y_classes.values)))\n",
    "    \n",
    "    batch_idx = batch_idx[:batch_size*n_split].reshape((n_split,batch_size, ))\n",
    "    batch_idx = batch_idx[:batch_size*n_split].reshape((n_split,batch_size, ))\n",
    "    \n",
    "    return batch_idx, val_idx\n",
    "\n",
    "    batch_idx, val_idx = (get_batch_idx(batches_idx,batch_size = 256))\n",
    "    batch_idx.shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential,load_model\n",
    "\n",
    "from keras.layers.core import Dense, Activation, Dropout, Highway, Reshape, Flatten, Lambda\n",
    "#from keras.layers.recurrent import LSTM, GRU, SimpleRNN\n",
    "#from keras.layers.wrappers import TimeDistributed\n",
    "#from keras.regularizers import l2, activity_l2\n",
    "\n",
    "# Hyperparameter Compile\n",
    "loss='mse' # 'hinge'\n",
    "optimizer='Nadam' #'rmsprop'\n",
    "\n",
    "# Hyperparameter Fit\n",
    "nb_epoch= 22\n",
    "\n",
    "#try:\n",
    "#    model = load_model('model.h5')\n",
    "#except:\n",
    "def model_1():\n",
    "        model = Sequential()\n",
    "        model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "            input_shape = image_shape,\n",
    "            output_shape= image_shape))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "        model.add(Activation('linear'))\n",
    "        return model\n",
    "\n",
    "model = model_1()\n",
    "\n",
    "\n",
    "%time model.compile(loss=loss, optimizer=optimizer)\n",
    "model.fit_generator(generator         = train_generator, \\\n",
    "                    samples_per_epoch = batch_size, \\\n",
    "                    validation_data   = validation_generator, \\\n",
    "                    nb_val_samples    = 1, \\\n",
    "                    nb_epoch          = nb_epoch)\n",
    "\n",
    "#train_generator, \n",
    "#samples_per_epoch= len(train_samples), \n",
    "#validation_data=validation_generator,\n",
    "#nb_val_samples=len(validation_samples), nb_epoch=3)\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    model.save_weights(\"model.h5\")\n",
    "except:\n",
    "    print(\"model.save_weights failed\")\n",
    "    \n",
    "    \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
